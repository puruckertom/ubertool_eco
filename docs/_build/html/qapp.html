<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>ubertool Quality Assurance Project Plan &mdash; übertool alpha documentation</title>
    
    <link rel="stylesheet" href="_static/ubertool.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'alpha',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="übertool alpha documentation" href="index.html" />
    <link rel="next" title="Publications" href="publications.html" />
    <link rel="prev" title="API" href="api.html" />
<!-- Browser FAVICON -->
  <LINK REL="SHORTCUT ICON" HREF="http://www.ubertool.org/static/images/favicon/ubertool/favicon.ico" />

  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="publications.html" title="Publications"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="api.html" title="API"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">übertool alpha documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="ubertool-quality-assurance-project-plan">
<h1>ubertool Quality Assurance Project Plan<a class="headerlink" href="#ubertool-quality-assurance-project-plan" title="Permalink to this headline">¶</a></h1>
<div class="section" id="project-management">
<h2>Project Management<a class="headerlink" href="#project-management" title="Permalink to this headline">¶</a></h2>
<div class="section" id="title-and-approval-sheet">
<h3>Title and Approval Sheet<a class="headerlink" href="#title-and-approval-sheet" title="Permalink to this headline">¶</a></h3>
<div class="section" id="title-of-qa-project-plan">
<h4>Title of QA Project Plan<a class="headerlink" href="#title-of-qa-project-plan" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="revision-number-of-qa-project-plan">
<h4>Revision number of QA Project Plan<a class="headerlink" href="#revision-number-of-qa-project-plan" title="Permalink to this headline">¶</a></h4>
<p>1.0</p>
</div>
<div class="section" id="effective-data-of-qa-project-plan">
<h4>Effective Data of QA Project Plan<a class="headerlink" href="#effective-data-of-qa-project-plan" title="Permalink to this headline">¶</a></h4>
<p>December 1, 2015</p>
</div>
<div class="section" id="names-of-all-organizations-involved-in-the-modeling-project">
<h4>Names of all organizations involved in the modeling project<a class="headerlink" href="#names-of-all-organizations-involved-in-the-modeling-project" title="Permalink to this headline">¶</a></h4>
<p>U.S. Environmental Protection Agency
Office of Research and Development
National Exposure Research Laboratory (NERL)
Ecosystems Research Division (ERD)
Athens, Georgia 30605 USA</p>
<p>U.S. Environmental Protection Agency
Office of Pesticide Programs
Ecological Fate and Effects Division (EFED)
Arlington, Virginia XXXXX USA</p>
</div>
<div class="section" id="names-of-all-key-project-officials-with-space-for-dated-signatures">
<h4>Names of all key project officials, with space for dated signatures<a class="headerlink" href="#names-of-all-key-project-officials-with-space-for-dated-signatures" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="table-of-contents-and-document-control-format">
<h3>Table of Contents and Document Control Format<a class="headerlink" href="#table-of-contents-and-document-control-format" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="distribution-list-a3">
<h3>Distribution List (A3)<a class="headerlink" href="#distribution-list-a3" title="Permalink to this headline">¶</a></h3>
<p>List of all individuals (and their role on the project) who will be provided copies of the approved QA Project
Plan, including all persons responsible for implementation, including project managers, QA Managers, and
representatives of all groups involved.
Bill Eckel
Nelson Thurman
John Johnston
QA Manager</p>
</div>
<div class="section" id="project-task-organization-a4">
<h3>Project/Task Organization (A4)<a class="headerlink" href="#project-task-organization-a4" title="Permalink to this headline">¶</a></h3>
<p>The übertool is a web application implementation of ecological risk models used by the EPA in pesticide registration
under FIFRA and for the assessment of pesticide risks to endangered species. Modern software development methods
are used to develop the web application, proceeding according to the principles of “scrum” development, an iterative
and incremental agile software development process for developing software applications (Lacey 2012). This approach
is centered around deploying applications in short time increments and getting rapid feedback from end users.  Both
of these occur at the end of each defined sprint period (4-6 weeks) in length. This deployment and feedback approach
is paired with modern industry standard approaches from XP programming and agile development.  XP programming
approaches include test-driven development, pair programming, collective code ownership, sustainable development
pace, coding standards, continuous integration, and code refactoring. Agile development processes include approaches
for</p>
<p>Scrum meetings are weekly on the same day every week (currently Thursday) at 3pm with monthly sprints replacing the
scrum meeting the first Thursday of every month.</p>
<p>Daily checkins are likely to be conducted on Google Hangout at 3pm for approximately 15 minutes.</p>
<p>Monthly ubertool progress reports are also scheduled with EFED via conference call.</p>
<p>There are three core roles involved in this process, these roles are:
- Product Owner: represents the stakeholders via stories backlog and priorities (Tom Purucker)
- Development Team: delivers product increments at the end of each sprint (ORISE fellowships working at the Athens
lab and others identified by Bill Eckel of OPP/EFED)
- Scrum Master: scrum facilitator who removes impediments for delivering sprint goals/deliverables, performs tasking,</p>
<blockquote>
<div>bug priority, task followup, etc. (contracted)</div></blockquote>
<p>Ancillary roles on the scrum team are:
- Stakeholders: (Bill Eckel, Ed Odenkirchen, Dirk Young, Nelson Thurman, Ron Parker, Katrina White, others
identified by Bill Eckel)
- Managers: People who control the environment (John Johnston [Branch Chief], Roy Sidle [Division Director],
John Kenneke [CSS Matrix Interface], Tina Bohardi [CSS], Jim Cowles [Associate Director at EFED])</p>
<p>Modern software development methods are used to develop the web application, proceeding according to the principles
of “scrum” development, an iterative and incremental agile software development process for developing software
applications (Lacey 2012). This approach is centered around deploying applications in short time increments and
getting rapid feedback from end users.  Both of these occur at the end of each defined sprint period (2-6 weeks)
in length. This deployment and feedback approach is paired with modern industry standard approaches from XP
programming and agile development.  XP programming approaches include test-driven development, pair programming,
collective code ownership, sustainable development pace, coding standards, continuous integration, and code
refactoring. Agile development processes include approaches for</p>
<p>Scrum meetings are weekly on the same day every week at 3pm with monthly sprints replacing the scrum meeting the
first Thursday of every month.  Daily checkins are likely to be conducted in Athens and via phone at 3pm EST for
approximately 15-30 minutes. Monthly ubertool progress reports are also scheduled with EFED via conference call.</p>
<p>There are three core roles involved in this process, these roles are:
* Product Owner: represents the stakeholders via stories backlog and priorities (Tom Purucker)
* Development Team: delivers product increments at the end of each sprint (EPA employees, ORISE fellows, and SSA
contractors working with ORD and EFED)
* Scrum Master: scrum facilitator who removes impediments for delivering sprint goals/deliverables, performs
tasking, bug priority, task followup, etc. (contracted)</p>
<p>EFED Stakeholders:</p>
<ul class="simple">
<li>Bill Eckel</li>
<li>Meridith Fry</li>
<li>Andrew Kanarek</li>
<li>Ed Odenkirchen</li>
<li>Michelle Thawley</li>
<li>Nelson Thurman</li>
<li>Dirk Young</li>
<li>others identified by Bill Eckel</li>
</ul>
<p>EPA Managers:</p>
<ul class="simple">
<li>Gerald [CED Division Director]</li>
<li>Tina Bohardi [CSS NPD]</li>
<li>Jim Cowles [Associate Director at EFED]</li>
<li>John Kenneke [CSS Matrix Interface]</li>
<li>Matt Etterson [CSS Ecological Modeling Project Lead]</li>
<li>John Johnston [WEB Branch Chief]</li>
</ul>
</div>
<div class="section" id="problem-definition-background-a5">
<h3>Problem Definition/Background (A5)<a class="headerlink" href="#problem-definition-background-a5" title="Permalink to this headline">¶</a></h3>
<p>Safety evaluations for pesticides are required for ecological and human health risks under a number of regulatory
statutes (e.g., Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA), Pesticide Registration improvement
Extension Act (PRIA 3), Federal food, Drug, and Cosmetic Act (FD&amp;C Act), Food Quality Protection Act (FQPA),
Endangered Species Act (ESA)). Ecological risk assessments under FIRFA and ESA are often implemented by the
Ecological Fate and Effects Division with OCSPP by accessing model tools and databases that have been developed
since the early 1980s on a range of software development platforms. These tools include Microsoft Excel
Spreadsheets, Windows-based interfaces, legacy Fortran code compiled as DOS executables, as well as programs
originally written in other programming languages (e.g., C, Perl, R). These models are parameterized with available
information from a number of different source data sets that also may vary in format. The results are documented
as risk assessment and management decisions for conventional active ingredients used in pesticide formulations.
The National Pesticide Program manages 1100 active ingredients and 19000 products that must be reevaluated on a
regular basis. The program also evaluates new pesticide formulations, ingredients, and novel uses of approved
active ingredients. The result of this process is that there are a large number of models to be run for many
chemicals with many possible adverse outcomes that must be summarized and reported. The current system of
distributed models and databases result in inefficiencies when conducting assessment and prevents transparency
regarding the evaluation process for regulatory risk evaluation.</p>
<div class="section" id="goals-and-objectives-of-this-project-that-will-address-this-problem">
<h4>Goals and objectives of this project that will address this problem<a class="headerlink" href="#goals-and-objectives-of-this-project-that-will-address-this-problem" title="Permalink to this headline">¶</a></h4>
<p>The objective of this effort is to implement appropriate technologies and update the source code base for the übertool,
a web application system that executes algorithms for pesticide registration and endangered species effects assessments,
so that it can be deployed in scalable computational environments that provide front end access to cloud-executed
models and database backbone capabilities for querying and storing parameter inputs/outputs. This system is to be
deployed internally within the EPA for government users and externally on a public-facing server for use by the
public, academia, and the regulated community. The intent of this implementation is to accomplish EPA goals
concerning transparency of the data analyses and scientific algorithm estimation components of the pesticide
registration process. The project vision is an Agency collaboration platform that serves as an integrated scientific
workflow application to implement relevant assessment methods, respond to changing empirical data availability
(e.g., required toxicity tests, bioassays) and incorporate current fate, exposure, and effect algorithms in a model
selection framework. Unlike the time-inefficient and outdated collection of legacy science components, this scientific
modeling platform will replace critical regulatory data analysis and modeling processes with a more efficient, 21st
century system at a reasonable cost.</p>
<p>Efficiently conduct environmental assessments for pesticide registration and endangered species effects assessments
for models that currently are deployed in a number of different ways (Fortran DOS executables, Windows programs,
Excel spreadsheets) using data from a number of different data sources.</p>
</div>
<div class="section" id="definition-of-the-population-the-problem-targets-and-what-measures-within-this-population-the-problem-addresses">
<h4>Definition of the population the problem targets and what measures within this population the problem addresses<a class="headerlink" href="#definition-of-the-population-the-problem-targets-and-what-measures-within-this-population-the-problem-addresses" title="Permalink to this headline">¶</a></h4>
<p>EFED risk assessors are the target audience for the ecological models. Main contacts include Bill Eckel,
Ed Odenkirchen, and Tom Steeger. Three divisions within OPP will use the human health version of the product-
HED, AD, and RD. Contacts include Vickie Dellarco, Jennifer McClain, Matt Lloyd, and Dana Vogel from the initial
meeting.</p>
<p>The ecological and human health divisions of OPP already share implementation of some of the models.
There may be instances where OPPT personnel used similar models as the OPP human health risk assessment divisions
and may use some of the models a la carte.  Members of the public, academia, and the registrants may use the product
via a public facing web page in the future.</p>
<p>As python code, it can be run on a computer locally using a web browser as an interface (without being on the Internet,
which will be necessary for the EPA to use it for applications involving confidential business information) and/or it
can be hosted on the Internet as a web domain so that the public can access the public domain models that are used to
determine pesticide registration and label restrictions (available at <a class="reference external" href="http://www.ubertool.org">http://www.ubertool.org</a>).  Component libraries
for the ubertool can be accessed individually in non-HTML applications.  Alternatively, the code could be hosted on an
EPA server with the requisite technologies to provide online access to the python code.  Regardless of how it is
accessed, some of the models (these are mostly older Fortran codes in the public domain, not web applications) are
of interest to the EPA pesticide office and could potentially realize significant efficiencies in regulating
pesticides, transparency for the ecological risk assessment process, and higher levels of quality assurance given
the larger audience that might use the models&#8211;whether for chemical regulation or for educational purposes.</p>
<p>Pesticide evaluations are required for ecological and human health risks under a number of regulatory statutes (e.g.,
Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA), Pesticide Registration improvement Extension Act
(PRIA 3), Federal Food, Drug, and Cosmetic Act (FD&amp;C Act), Food Quality Protection Act (FQPA), Endangered Species
Act (ESA)). Ecological risk assessments under FIRFA and ESA are often implemented by the Ecological Fate and
Effects Division within the Office of Chemical Safety and Pollution Prevention by accessing model tools and
databases that have been in continual development since the early 1980s on a range of software development platforms.
These tools include Microsoft Excel Spreadsheets, Windows-based interfaces, legacy Fortran code compiled as DOS
executables, as well as programs originally written in other programming languages (e.g., C, Perl, R). These models
are parameterized with available information from a number of different source data sets that also may vary in format.
The results are documented as risk assessment and management decisions for conventional active ingredients used in
pesticide formulations. The National Pesticide Program manages 1100 active ingredients and 19000 products that must
be reevaluated on a regular basis. The program also evaluates new pesticide formulations, ingredients, and novel uses
of approved active ingredients. The result of this process is a large number of models to be run for many chemicals
with many possible adverse outcomes that must be summarized and reported. The current system of distributed models
and databases result in inefficiencies when conducting assessment and prevents transparency regarding the evaluation
process for regulatory risk evaluation.</p>
<p>The decision to register a pesticide is based on the consideration of scientific data and other factors showing that
it will not cause unreasonable risks to human health, workers, or the environment when used as directed on product
labeling. The registration review program is intended to ensure that, as the ability to assess risk evolves and as
policies and practices change, all registered pesticides continue to meet the statutory standard of no unreasonable
adverse effects to human health and the environment. Changes in science, public policy, and pesticide use practices
occur over time. Through the registration review program, EPA periodically reevaluates pesticides to ensure that as
change occurs, products in the marketplace can be used safely. As part of the registration review process, EFED
assesses risks of pesticides to Federally-listed threatened and/or endangered (listed) species from registered uses
of pesticides.  These assessments are conducted in accordance with provisions of the Endangered Species Act (ESA),
and the Services’ Endangered Species Consultation Handbook (NMFS). The models used are periodically updated in
view of new pesticides, changing science, and as novel exposure pathways come to light.</p>
</div>
<div class="section" id="reason-the-project-includes-a-modeling-approach-to-address-the-problem-is-it-a-new-predictive-tool">
<h4>Reason the project includes a modeling approach to address the problem (is it a new predictive tool?)<a class="headerlink" href="#reason-the-project-includes-a-modeling-approach-to-address-the-problem-is-it-a-new-predictive-tool" title="Permalink to this headline">¶</a></h4>
<p>EPA is responsible for registering pesticides under FIFRA; as part of the registration process, the EPA’s Ecological
Fate and Effects Division of the Office of Chemical Safety and Pollution is responsible for analyzing data and
developing/ implementing ecological models that estimate risks to non-target receptors. The Food Quality Protection
Act of 1996 mandated the Environmental Protection Agency (EPA) to implement a new program for assessing the risks of
pesticides, registration review. The decision to register a pesticide is based on the consideration of scientific data
and other factors showing that it will not cause unreasonable risks to human health, workers, or the environment when
used as directed on product labeling. The registration review program is intended to ensure that, as the ability to
assess risk evolves and as policies and practices change, all registered pesticides continue to meet the statutory
standard of no unreasonable adverse effects to human health and the environment. Changes in science, public policy,
and pesticide use practices will occur over time. Through the new registration review program, EPA periodically
reevaluates pesticides to ensure that as change occurs, products in the marketplace can be used safely. As part
of the registration review process, EFED is assessing risks of pesticides to Federally-listed threatened and/or
endangered (listed) species from registered uses of pesticides.  These assessments are conducted in accordance
with the Overview Document[1], provisions of the Endangered Species Act (ESA), and the Services’ Endangered
Species Consultation Handbook (NMFS 1998). The models used are periodically updated in view of new pesticides,
changing science, and as novel exposure pathways come to light.</p>
<p>created an integrated web-based tool, the übertool, designed to estimate exposure doses and ecological risks
under the Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA) and the Endangered Species Act (ESA).
This involved combining a number of individual software models into web applications so they can be more
easily parameterized, run, and documented by the EPA regulatory program office as well as federal,
industry, and academic researchers outside the agency. These models include a range of aquatic, terrestrial,
and atmospheric deposition fate and transport models used to estimate pesticide exposures and effects for a wide
range of ecological receptors. Risk assessments based on these models are evaluated when seeking approval for
pesticide formulations by the Environmental Protection Agency (EPA). Übertool integration of the ecological
risk models creates a unified environment where data inputs and outputs are shared amongst models and saved
for each user. This web-based approach takes advantage of new technologies including on-demand cloud computation
of models written in a variety of programming languages (e.g., Python, Fortran, C) as well as spreadsheet calculators
(e.g., Microsoft Excel) to support complex and screening level models. The übertool can also batch run multiple
models simultaneously given the appropriate inputs providing an efficient and previously unavailable ecological
risk service.</p>
<p>Übertool’s web-based framework has also extended to population dynamic models not currently used by FIFRA and
ESA that are publicly available for educational and research purposes. Traditionally, ecological assessment
of pesticides is based on the ratio between estimated environmental concentrations and extrapolated toxicity
effects levels that can be difficult to relate to ecological endpoints that are actually valued and regulated
(e.g., populations).  By aggregating these models into a virtual dashboard, we enable linkages to be created
in the gap between the traditional ecological hazard assessment of screening models (risk quotients) and
assessing ecological endpoints at the population level. Closing this gap has been identified in a recent
National Academy of Science’s report as being necessary to create a common, scientifically credible approach
to resolve discrepancies between how FIFRA and the ESA manage ecological risks. The new framework (Untertool)
incorporates a variety of models including basic models of population dynamics (e.g. logistic model), intra-colony
honey bee population dynamic models, and links to other online models and resources.</p>
</div>
<div class="section" id="types-of-decisions-that-may-be-made-as-a-result-of-this-project">
<h4>Types of decisions that may be made as a result of this project<a class="headerlink" href="#types-of-decisions-that-may-be-made-as-a-result-of-this-project" title="Permalink to this headline">¶</a></h4>
<p>The EPA is dependent on multiple scientific computational models for the environmental regulatory process of chemicals
and laws that codify ecological and human health protection standards. Laws include the Federal Insecticide, Fungicide,
and Rodenticide Act (FIFRA), Endangered Species Act (ESA), Toxic Substances Control Act (TSCA) and the Federal Food,
Drug and Cosmetic Act (FFDCA). More often than not, the effective basis of such standards are decisions about the
selection and application of data and computational models. Over time, the relevant laws, data and computational
models have evolved due to increased complexity of EPA regulations and scenario-dependent implementations. This
complexity leaves a legacy of computational models, still relevant to the regulatory process, varied with incompatible
computer languages and software that are not easily integrated or updated as the science evolves. These limitations
are addressed by integrating EPA’s existing and developing regulatory models into a unified science application
platform known as the ubertool.</p>
</div>
<div class="section" id="any-other-types-of-problems-that-the-project-may-address">
<h4>Any other types of problems that the project may address<a class="headerlink" href="#any-other-types-of-problems-that-the-project-may-address" title="Permalink to this headline">¶</a></h4>
<p>The science models in the ubertool provide testable predictions concerning chemical concentrations in environmental
media, exposure doses, tissue residues and ultimately predictions of effects. These predictions are relevant for a
number of ecological species under regulations that the EPA is responsible for - including FIFRA, ESA, FFDCA, and the
FQPA. These model predictions can be tested by comparing them to relevant data from laboratory, field and/or modeling
investigations. From an exposure perspective, improvements to this core set of models can come in different forms &#8211;
they may include:</p>
<ul class="simple">
<li>better algorithms: algorithmic improvements to core EPA ecological models (e.g., updated versions of T-Rex, PRZM,</li>
</ul>
<p>EXAMS), many of which were initially developed at ORD, to provide better predictive capability or extend their use
to new exposure settings,
- identifying novel exposure areas: (receptors, environments) not adequately covered by the current set of ecological
models (e.g., ongoing research for amphibians and honeybees),
better input data: finding new data sources that improve ecological model (e.g., molecular bioassay endpoints, -omics
applications, propose/modify/eliminate specific registrant data submittal requirements),
- scaling exposure processes: enable applications of existing models in spatially and temporally realistic settings
at scale (e.g., SAM applications for endangered species), and/or
- replace existing models: evaluating proposed replacements for models that are currently used in pesticide
registration decisions via model selection processes.
All of these improvements require execution of the existing models in order to scientifically demonstrate model
enhancements in a reproducible manner. The primary goal of these studies is to minimize false positive and false
negative pesticide registration decisions made by the Agency, so the relevance of these types of scientific
exercises is very high.</p>
</div>
<div class="section" id="background-information-on-the-problem">
<h4>Background information on the problem<a class="headerlink" href="#background-information-on-the-problem" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div>EPA (2004) provides an overview of OPP’s ecological risk assessment process:</div></blockquote>
<p>www.epa.gov/espp/consultation/ecorisk-overview.pdf</p>
</div>
<div class="section" id="reasons-the-project-is-important-how-it-supports-other-existing-research-programs-or-regulations">
<h4>Reasons the project is important, how it supports other existing research, programs, or regulations<a class="headerlink" href="#reasons-the-project-is-important-how-it-supports-other-existing-research-programs-or-regulations" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="conflicts-or-uncertainties-that-will-be-resolved-by-this-project">
<h4>Conflicts or uncertainties that will be resolved by this project<a class="headerlink" href="#conflicts-or-uncertainties-that-will-be-resolved-by-this-project" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="reasons-one-model-is-determined-to-be-better-than-another-for-this-application">
<h4>Reasons one model is determined to be better than another for this application<a class="headerlink" href="#reasons-one-model-is-determined-to-be-better-than-another-for-this-application" title="Permalink to this headline">¶</a></h4>
<p>The program office uses them, after a review process...</p>
</div>
</div>
<div class="section" id="project-task-description-and-schedule-a6">
<h3>Project/Task Description and Schedule (A6)<a class="headerlink" href="#project-task-description-and-schedule-a6" title="Permalink to this headline">¶</a></h3>
<div class="section" id="summary-of-all-work-to-be-performed-products-to-be-produced-and-the-schedule-for-implementation">
<h4>Summary of all work to be performed, products to be produced, and the schedule for implementation<a class="headerlink" href="#summary-of-all-work-to-be-performed-products-to-be-produced-and-the-schedule-for-implementation" title="Permalink to this headline">¶</a></h4>
<p>To create an aggregate ubertool assessment, a user will have created the above data objects for each of the
tables above, and will combine them to create a batched assessment.  A tree with dropdown comboboxes that reflect
available data objects saved to the user account will be presented to the user.  By selecting an appropriate data
object for each of the 8 data node objects on the tree, the user can then execute the aggregate ubertool to run the
included models.  At this point, there will be no option to deselect a constituent model in the aggregate ubertool.
We need a figure of a mock-up of the ubertool aggregate data tree.</p>
<p>An additional priority is development of the spatial overlay tool to compare endangered species ranges to crop and
pesticide application distributions.  This will develop will proceed separately from the aggregate ubertool initially.</p>
<p>A future priority is using the fate and transport models to create exposure concentrations data objects that are used
by a number of the ecological models.</p>
</div>
<div class="section" id="list-of-products-deliverables-and-milestones-to-be-completed-in-the-various-stages-of-the-project">
<h4>List of products, deliverables, and milestones to be completed in the various stages of the project<a class="headerlink" href="#list-of-products-deliverables-and-milestones-to-be-completed-in-the-various-stages-of-the-project" title="Permalink to this headline">¶</a></h4>
<p>The ubertool is developed in an iterative development environment, so that new releases of the web application are
distributed every 3 weeks at the conclusion of each sprint.</p>
</div>
<div class="section" id="schedule-of-anticipated-start-and-completion-dates-for-the-milestones-and-deliverables-and-persons-responsible-for-each">
<h4>Schedule of anticipated start and completion dates for the milestones and deliverables, and persons responsible for each<a class="headerlink" href="#schedule-of-anticipated-start-and-completion-dates-for-the-milestones-and-deliverables-and-persons-responsible-for-each" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>Code all constituent (OPP/ORD) models in Python and Fortran based on available code, users’ manuals, and qapps into a single library (complete).</li>
<li>Host all models in library on a back end rest server (bottle) so they can be called from a web browser session (complete).</li>
<li>Create front end instances (django) for all the models so that they can be fed input data and run in a web browser (complete).</li>
<li>Create parameter crosswalk between all model inputs and outputs for qaqc purposes (complete).</li>
<li>Create database system (mongodb) to record individual model inputs and outputs persistently for all user-based execution (complete).</li>
<li>Initiate OEI/NCC application deployment checklist process (complete): <a class="reference external" href="http://cfint.rtpnc.epa.gov/adc/reviewcenter/index.cfm?ADCNumber=3146">http://cfint.rtpnc.epa.gov/adc/reviewcenter/index.cfm?ADCNumber=3146</a></li>
<li>Deploy front and back end model services to multiple CGI servers (complete).</li>
<li>Use parameter crosswalk as template to collect qaqc input/output test case scenarios, 10 per model (complete).</li>
<li>Public demonstration of tool to industry at EFED workshop (October 29, 2014) (complete): <a class="reference external" href="https://www.federalregister.gov/articles/2014/10/08/2014-24026/spatial-aquatic-model-development-notice-of-public-meeting">https://www.federalregister.gov/articles/2014/10/08/2014-24026/spatial-aquatic-model-development-notice-of-public-meeting</a></li>
<li>Submit system security plan to OEI (complete).</li>
<li>Submit syscat categorizations for all models to OSIM/OEI (complete).</li>
<li>Pass system vulnerability scans performed by NCC (complete).</li>
<li>Add disclaimers regarding beta status of models (complete).</li>
<li>Setup dns, apache and nginx configurations so that epa can route traffic to appropriate cgi cloud hosted implementations (complete).</li>
<li>Submit firewall rule request for ports 80, 443 (22) to allow public access. (complete, but temporary), available on intranet and internet at <a class="reference external" href="http://qed.epa.gov/ubertool">http://qed.epa.gov/ubertool</a></li>
<li>Public workshop with industry and others providing comment on current status of tool (April 29, 2015) (complete): <a class="reference external" href="https://www.federalregister.gov/articles/2015/04/03/2015-07645/spatial-aquatic-model-development-notice-of-public-meeting">https://www.federalregister.gov/articles/2015/04/03/2015-07645/spatial-aquatic-model-development-notice-of-public-meeting</a></li>
<li>Implement betatester password protected input pages to restrict public (internet, not intranet) execution of models to those with a password (will complete on 6/12/2015).</li>
<li>Resubmit permanent firewall rule request for internet access (June 2015).</li>
<li>Migration from CGI NCC contract to CGI general services contract, redeploy all servers to more modern (more secure) EPA red hat enterprise linux implementations (July 2015).</li>
<li>Implement qa/qc testing against previously gathered test cases (mostly complete, but being refactored for efficiency). Automate for daily execution.</li>
<li>Ongoing Spatial Aquatic Model code changes in collaboration with EFED (ongoing).</li>
<li>SSL encryption of all traffic (port 443) (Fall 2015).</li>
<li>NERL web application clearance process (to be defined by David Kryak et al) (Winter 2015-2016).</li>
<li>Remove betatester authentication on approved models (Spring 2016).</li>
<li>Public rollout of ubertool (late Spring 2016).</li>
</ul>
</div>
</div>
<div class="section" id="quality-objectives-and-criteria-for-model-inputs-outputs-a7">
<h3>Quality Objectives and Criteria for Model Inputs/Outputs (A7)<a class="headerlink" href="#quality-objectives-and-criteria-for-model-inputs-outputs-a7" title="Permalink to this headline">¶</a></h3>
<div class="section" id="project-data-quality-objectives-dqos-performance-criteria-and-acceptance-criteria">
<h4>Project data quality objectives (DQOs), performance criteria, and acceptance criteria<a class="headerlink" href="#project-data-quality-objectives-dqos-performance-criteria-and-acceptance-criteria" title="Permalink to this headline">¶</a></h4>
<p>All model components will be developed using an appropriate approach to quality assurance and documentation.</p>
</div>
<div class="section" id="description-of-task-that-needs-to-be-addressed-and-the-intended-uses-of-the-output-of-the-modeling-project-to-achieve-the-task">
<h4>Description of task that needs to be addressed and the intended uses of the output of the modeling project to achieve the task<a class="headerlink" href="#description-of-task-that-needs-to-be-addressed-and-the-intended-uses-of-the-output-of-the-modeling-project-to-achieve-the-task" title="Permalink to this headline">¶</a></h4>
<p>The EPA registers pesticides for use in the US under applicable federal laws. To assess potential risks, mathematical
models are used to predict pesticide concentrations in different media and ultimately predict effects to non-target
species.  The suite of models that the EPA uses has been in development since the 1980s, with a wide range of
algorithmic complexity and technical implementation from Fortran executables to Microsoft Excel spreadsheets. We have
updated these models to create an application programming interface (API) that is accessible via a web service
implementation. Hosted in the cloud, the application combines relevant spatial information, chemical properties,
ecological exposure parameters, pesticide use properties, and effects data into a decision support “dashboard.”
The system is a platform-as-a-service implementation and is available to users through the use of modern web
technologies that allow cloud-based ecological pesticide models and data to be accessed with a web browser.</p>
<p>The larger outcome is that scientists with original ideas, models, data, and tools no longer have to secure significant
resources for hardware and application programmers to ensure that “translational” research can find a use in regulatory
decision support structures. This availability will lead to better data and model selection decisions and a more robust,
defensible regulatory frameworks. The resulting dashboards can increase decision-making transparency and serve as a
conduit for translating science improvements to the regulatory process &#8211; all while functioning in production mode as
a form of “Science-as-a-Service” to provide the necessary assessment tools for environmental regulation.</p>
<div class="section" id="ecological-models">
<h5>Ecological Models<a class="headerlink" href="#ecological-models" title="Permalink to this headline">¶</a></h5>
<p>A number of models are used to estimate risk to non-target species in this process.  These models are listed in Table
1 and their current development status within the ubertool.</p>
<p>Table 1. Models in version 1 of the ubertool
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id36"><span class="problematic" id="id37">|Model         | Purpose     |
+==============+=============+
|TerrPlant     |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|Sip           |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|Stir          |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|T-Rex|</span></a>        |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id38"><span class="problematic" id="id39">|T-Herps       |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|IEC           |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|AgDrift       |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|AgDrift-TRex  |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
|AgDrift-THerps|</span></a>             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id1"><span class="problematic" id="id2">|</span></a>Earthworm     |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id3"><span class="problematic" id="id4">|</span></a>Rice          |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id5"><span class="problematic" id="id6">|</span></a>Kabam         |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id7"><span class="problematic" id="id8">|</span></a>PFAM          |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id9"><span class="problematic" id="id10">|</span></a>SAM           |             |
+&#8212;&#8212;&#8212;&#8212;&#8211;+&#8212;&#8212;&#8212;&#8212;-+</p>
<p>Table 2. Candidate models for the untertool
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id11"><span class="problematic" id="id12">|</span></a>Model     | Purpose        |
+==========+================+
<a href="#id13"><span class="problematic" id="id14">|</span></a>EXAMS     |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id15"><span class="problematic" id="id16">|</span></a>PRZM      |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id17"><span class="problematic" id="id18">|</span></a>Geneec    |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id19"><span class="problematic" id="id20">|</span></a>VVWM      |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id21"><span class="problematic" id="id22">|</span></a>First     |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id23"><span class="problematic" id="id24">|</span></a>DUST      |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id25"><span class="problematic" id="id26">|</span></a>TIM       |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id27"><span class="problematic" id="id28">|</span></a>DDM       |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id29"><span class="problematic" id="id30">|</span></a>PlantX    |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id31"><span class="problematic" id="id32">|</span></a>Bee-Rex   |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+
<a href="#id33"><span class="problematic" id="id34">|</span></a>SuperPRZM |                |
+&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;&#8212;-+</p>
<p>Table 3. Population models
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
<a href="#id40"><span class="problematic" id="id41">|Model                             | Purpose     |
+==================================+=============+
|Exponential                       |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Logistic                          |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Gompertz                          |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Fox Surplus Yield                 |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Maximum Sustainable Yield         |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Yule-Furry Markov Process         |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Feller-Arley Markov Process       |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Leslie Projection Matrix          |             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+
|Leslie with Logistic Dose Response|</span></a>             |
+&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-+&#8212;&#8212;&#8212;&#8212;-+</p>
</div>
<div class="section" id="database-sources">
<h5>Database Sources<a class="headerlink" href="#database-sources" title="Permalink to this headline">¶</a></h5>
<p>It will be necessary to crosswalk the data that is available in the database sources with the listed data object tables. The crosswalk is available at <a class="reference external" href="http://tiny.cc/ubertool_crosswalk">http://tiny.cc/ubertool_crosswalk</a></p>
<p>Database backbone details (MongoDB, possibly Amazon-based via EC2) and mapping technologies (maybe Google maps plus postgis/postgresql) are still undecided.
<a class="reference external" href="http://www.mongodb.org/display/DOCS/Amazon+EC2">http://www.mongodb.org/display/DOCS/Amazon+EC2</a>
<a class="reference external" href="http://aws.amazon.com/rds/">http://aws.amazon.com/rds/</a>
<a class="reference external" href="https://developers.google.com/maps/documentation/webservices/">https://developers.google.com/maps/documentation/webservices/</a>
<a class="reference external" href="http://postgis.refractions.net/">http://postgis.refractions.net/</a>
<a class="reference external" href="http://www.postgresql.org/">http://www.postgresql.org/</a></p>
<p>Table 4. Available databases with parameters of interest</p>
<p>Database        Location        Description
Ecological Incident Information System  C:Documents and SettingsAll UsersprogramsEIISEIISv2.1.mdb  Data on incidents of adverse field effects plants and wild animals. (Nick Mastrota)
Avian Incident Monitoring System        http://www.abcbirds.org/abcprograms/policy/pesticides/aims/aims/index.cfm       An American Bird Conservancy database of avian incidents. (Nick Mastrota)
Pesticide Ecotoxicity Database  G:Science DatabasesEcotoxicityToxdataEcoToxData.mdb        Data of toxicity of pesticides to plants and animals from EPA-reviewed studies. (Brian Montague)
Pesticide Fate Database http://cfpub.epa.gov/pfate/home.cfm     Environmental fate data from EPA-reviewed studies. (Larry Liu)
EFED Ingredients        N:EFED_ApplicaitionsdatabasesEFED IngredientsEFED Ingredients.mdb   Data on pesticide ingredients reviewed by EFED. (Nick Mastrota)
LOCATES C:Documents and SettingsAll UsersprogramsLOCATESLOCATES FE.mdb     Co-ocurrence of endangered species and crop locations. (Kurt Pluntke)
EFED library    G:Information ResourcesEFED LibraryEFED Library.mdb Information on books and articles in the EFED library. (Nick Mastrota)
ChemFiles       N:EFED_ApplicationsdatabasesChemFilesChemFiles_FE.mdb       Tracking data on EFED’s chemical files. (Nick Mastrota)
Birds in Agricultural Areas     http://www.abcbirds.org/abcprograms/policy/pesticides/biaa/index.html   An American Bird Conservancy database of use of crops by birds. (Brian Montague)
STORET  http://www.epa.gov/storet       An EPA database of water quality data from U.S. surface and ground water monitoring. (Nelson Thurman)
LUIS</p>
</div>
</div>
<div class="section" id="list-of-requirements-associated-with-the-hardware-software-configuration-for-those-studies-involving-software-evaluation">
<h4>List of requirements associated with the hardware/software configuration for those studies involving software evaluation<a class="headerlink" href="#list-of-requirements-associated-with-the-hardware-software-configuration-for-those-studies-involving-software-evaluation" title="Permalink to this headline">¶</a></h4>
<p>Python uses web application frameworks that conform to a common standard called the Web Server Gateway Interface
(WSGI).  We currently use two frameworks, webapp2 and Django, that help automate the integration of the Python backend
and the web application frontend allowing for rapid development.</p>
<p>Web hosting services provide the cloud storage and host the web site containing the web applications.  These web
services are vital to the übertool in terms of accessibility and data processing.  The Python web application
frameworks work with the web hosting services to ultimately provide the deliverable to the end user.</p>
<p>The nature of web application development allows for the use of many cross-platform (i.e. Microsoft Windows, Apple
OSX, Redhat Linux, etc.) software programs.  Python itself is a cross-platform language designed to easily integrate
various programming languages.  The software development environment includes text editors such as Sublime Text,
Python IDEs such as Spyder, Python extensions such as NumPy, and web browsers such as Microsoft’s Internet Explorer,
Google’s Chrome, and Mozilla’s Firefox.</p>
<p>The source code for the übertool is version controlled using GitHub.  GitHub manages all changes to the source code,
allowing for simultaneous development from multiple developers on the same source code.  Each developer has his/her
own “branch” of the source code on which they work.  These branches are merged back into the “trunk” or master
branch of the source code as the software is updated.  Software can be rolled back as necessary as GitHub tracks
the history of the software development.</p>
<p>The übertool is requires database support for full functionality.  The database of choice is MongoDB as it is
cross-platform, flexible, and open source.</p>
<p>Environmental models may require the ability to scale their implementation. This may be in response to a need to
execute more complex, detailed applications and/or be responsive to multiple users in a distributed modeling setting.
Regardless, such implementations may require a combination of significant core computing capacity and concurrency
control that is difficult to achieve in a desktop environment. Scaling these models can present challenges, but
may be necessary for Monte Carlo simulation, for higher spatial resolution and/or geographical scale, long time
series modeling, and/or to account for multiple simultaneous users.</p>
<p>This hands-on workshop will allow users to deploy a combination of modern technologies that can address these
issues. Participants will quickly build a running instance on their laptop of the leading containerization technology,
Docker, in order to deploy a set of environmental models.  Container-based technologies separate the application
from the underlying infrastructure, just like virtual machines separate the host operating system from the underlying
hardware. These technologies allow for the ability to build and configure an environmental model once, and then
deploy and run the model anywhere. The core services consist of a daemon that is installed on a machine and a
client that interacts with the daemon. A typical workflow then consists of a containerized image that is layered
to contain the host operating system, environmental model(s), and all dependencies. Images are used to create
containers that can be started, stopped, moved or deleted. This technology is supported by a registry system that
allows for public or private access to repositories that store images as well as a system for automating building
images. This lightweight approach is portable and scalable, with the ability to launch and shut down additional
machines as needed.</p>
<p>To fully leverage this technology, the models in the containerization image will be in the form of application
programming interface (API) representation state transfer (RESTful) web services. We will address approaches for
accessing these endpoints and leveraging their deployment within cloud environments, providing Models-as-a-Service.
RESTful endpoints opens up a number of possibilities for scaling computations and allow for model interoperability
possibilities at both the computational/ algorithmic  level and from a user interface (mobile, desktop or web)
development standpoint.</p>
</div>
</div>
<div class="section" id="special-training-requirements-certification-a8">
<h3>Special Training Requirements/Certification (A8)<a class="headerlink" href="#special-training-requirements-certification-a8" title="Permalink to this headline">¶</a></h3>
<div class="section" id="types-of-required-training-and-certification-needed-by-the-project-team">
<h4>Types of required training and certification needed by the project team<a class="headerlink" href="#types-of-required-training-and-certification-needed-by-the-project-team" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="plan-for-obtaining-training-and-or-certification">
<h4>Plan for obtaining training and/or certification<a class="headerlink" href="#plan-for-obtaining-training-and-or-certification" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="documentation-of-training-and-or-certification">
<h4>Documentation of training and/or certification<a class="headerlink" href="#documentation-of-training-and-or-certification" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="documentation-and-records-a9">
<h3>Documentation and Records (A9)<a class="headerlink" href="#documentation-and-records-a9" title="Permalink to this headline">¶</a></h3>
<p>Project progress will be documented annually in terms of the annual reports. In addition, conference presentations and
publications will be prepared as appropriate and archived in the EPA knowledge management systems (Google doc?,
github wiki?).</p>
<p>An updated version of the quality assurance plan will be developed annually and distributed by email. The date of the
latest update will be included in the plan. Records of yearly quality assurance audits performed by the QA manager
and QA officer are maintained by the QA manager. The auditor uses a checklist to mark which portions of the QAPP are
followed, and to document deviations or absence of any QA measures. The results of such audits shall be documented and
filed by the Quality Assurance Manager. The audit process itself shall be designed to objectively measure compliance
with written procedures and assess the effectiveness of the process. The evaluation shall include interviews with
development team members, and a review of research project work and quality records.</p>
<p>Before submission of a paper to an archival journal, the work will be reviewed for conformance with the applicable
quality assurance criteria. Program code and output will be maintained in electronic data files and backed up on
cloud platform (www.github.com). These documents will be maintained for a minimum of 5 years after the completion
of the project.</p>
<div class="section" id="description-of-information-to-be-included-in-reports">
<h4>Description of information to be included in reports<a class="headerlink" href="#description-of-information-to-be-included-in-reports" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="proper-document-control-and-distribution-procedures">
<h4>Proper document control and distribution procedures<a class="headerlink" href="#proper-document-control-and-distribution-procedures" title="Permalink to this headline">¶</a></h4>
<p>github</p>
</div>
<div class="section" id="details-on-document-storage">
<h4>Details on document storage<a class="headerlink" href="#details-on-document-storage" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="backup-plan-for-records-stored-electronically">
<h4>Backup plan for records stored electronically<a class="headerlink" href="#backup-plan-for-records-stored-electronically" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="description-of-the-change-control-process-who-approves-changes-etc">
<h4>Description of the change control process (who approves changes, etc.)<a class="headerlink" href="#description-of-the-change-control-process-who-approves-changes-etc" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="length-of-retention-periods-for-each-record">
<h4>Length of retention periods for each record<a class="headerlink" href="#length-of-retention-periods-for-each-record" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="data-assessment-reports-interim-project-progress-reports">
<h4>Data assessment reports, interim project progress reports<a class="headerlink" href="#data-assessment-reports-interim-project-progress-reports" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="model-science-formulation-report-peer-review-reports">
<h4>Model science formulation report, peer review reports<a class="headerlink" href="#model-science-formulation-report-peer-review-reports" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="model-assessment-reports-interim-project-progress-reports">
<h4>Model assessment reports, interim project progress reports<a class="headerlink" href="#model-assessment-reports-interim-project-progress-reports" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="code-standards-code-auditing-and-testing-reports-interim-project-progress-reports">
<h4>Code standards, code auditing and testing reports, interim project progress reports<a class="headerlink" href="#code-standards-code-auditing-and-testing-reports-interim-project-progress-reports" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div>Potential collaboration/development tools include:</div></blockquote>
<ul class="simple">
<li>kunagi (agile/scrum management system)</li>
</ul>
<p><a class="reference external" href="http://kunagi.org/">http://kunagi.org/</a>
- chiliproject (bug and feature tracking for agile development and quality)
<a class="reference external" href="https://www.chiliproject.org/">https://www.chiliproject.org/</a>
- jenkins (continuous integration and testing server)
<a class="reference external" href="http://jenkins-ci.org/">http://jenkins-ci.org/</a>
- sonar (code quality/bug prevention)
<a class="reference external" href="http://www.sonarsource.org/">http://www.sonarsource.org/</a>
- teambox collaboration (ubertool project currently active)
<a class="reference external" href="http://teambox.com/">http://teambox.com/</a>
- Google hangout (requires a Google+ account)
<a class="reference external" href="http://www.google.com/+/learnmore/hangouts/">http://www.google.com/+/learnmore/hangouts/</a></p>
<p>Some of these development tools may be accessible through ubertool subdomains in order to allow access from within the
EPA firewall.</p>
</div>
<div class="section" id="model-calibration-report">
<h4>Model calibration report<a class="headerlink" href="#model-calibration-report" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="model-evaluation-records-how-well-does-the-model-report-variability-and-uncertainty-in-its-output">
<h4>Model evaluation records (How well does the model report variability and uncertainty in its output?)<a class="headerlink" href="#model-evaluation-records-how-well-does-the-model-report-variability-and-uncertainty-in-its-output" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="users-manual">
<h4>User’s manual<a class="headerlink" href="#users-manual" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="configuration-management-after-production-version-and-code-maintenance-e-g-or-software-internal-documentation-of-logic-and-structure-manuals">
<h4>Configuration management (after production version) and code maintenance (e.g., or software internal documentation of logic and structure) manuals<a class="headerlink" href="#configuration-management-after-production-version-and-code-maintenance-e-g-or-software-internal-documentation-of-logic-and-structure-manuals" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="licensing-issues">
<h4>Licensing Issues<a class="headerlink" href="#licensing-issues" title="Permalink to this headline">¶</a></h4>
<p>There are still a lot of questions about the use of open source licenses by federal agencies. If the software is
developed solely by government employees, the questions are even more open.  A developer can release software under
an OSS because he or she has a copyright in the software, a property right that can be licensed.  A government work,
like employee-developed software, is not entitled to U.S. copyright protection.   NASA and others address this dilemma
with this argument: The software is still property (if not intellectual property) of the U.S. government.  Since the
U.S. government can choose not to release its property, it can also choose to release it only under the conditions of
a license.</p>
</div>
</div>
</div>
<div class="section" id="group-b-measurement-and-data-acquisition">
<h2>GROUP B: Measurement and Data Acquisition<a class="headerlink" href="#group-b-measurement-and-data-acquisition" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt>This project is based entirely on modeling with existing publicly available mathematical and empirical</dt>
<dd>models and therefore follows the Guidance for Quality Assurance Project Plans for Modeling</dd>
</dl>
<p>EPA QA/G-5m (USEPA, 2002). The project relies exclusively on secondary sources of data, also
referred to as non-direct measurements, for parameterization. Most of this information is submitted to the EPA from
registrants or publicly available with their own documented quality control
procedures. Some data utilized from public and private sources that may have less well
documented quality assurance procedures.</p>
<div class="section" id="sampling-process-design-b1">
<h3>Sampling Process Design (B1)<a class="headerlink" href="#sampling-process-design-b1" title="Permalink to this headline">¶</a></h3>
<p>This section pertains to the acquisition of primary data and is not applicable to this project.</p>
</div>
<div class="section" id="sampling-methods-b2">
<h3>Sampling Methods (B2)<a class="headerlink" href="#sampling-methods-b2" title="Permalink to this headline">¶</a></h3>
<p>This section pertains to the acquisition of primary data and is not applicable to this project.</p>
</div>
<div class="section" id="sampling-handling-and-custody-b3">
<h3>Sampling Handling and Custody (B3)<a class="headerlink" href="#sampling-handling-and-custody-b3" title="Permalink to this headline">¶</a></h3>
<p>This section pertains to the acquisition of primary data and is not applicable to this project.</p>
</div>
<div class="section" id="analytical-methods-b4">
<h3>Analytical Methods (B4)<a class="headerlink" href="#analytical-methods-b4" title="Permalink to this headline">¶</a></h3>
<p>This section pertains to the acquisition of primary data and is not applicable to this project.</p>
</div>
<div class="section" id="quality-control-b5">
<h3>Quality Control (B5)<a class="headerlink" href="#quality-control-b5" title="Permalink to this headline">¶</a></h3>
<p>This section pertains to the acquisition of primary data and is not applicable to this project.</p>
</div>
<div class="section" id="instrument-equipment-testing-inspection-and-maintenance-b6">
<h3>Instrument/Equipment Testing, Inspection, and Maintenance (B6)<a class="headerlink" href="#instrument-equipment-testing-inspection-and-maintenance-b6" title="Permalink to this headline">¶</a></h3>
<p>This section pertains to the acquisition of primary data and is not applicable to this project.</p>
</div>
<div class="section" id="calibration-b7">
<h3>Calibration (B7)<a class="headerlink" href="#calibration-b7" title="Permalink to this headline">¶</a></h3>
<p>A key component for science is reproducibility. So, the science infrastructure worthy of the award would not be a
“secret science” application executed in an infrastructure that only we hold the key to, instead the computations
would be (first internally, then) publicly available in a reproducible manner that facilitates the comparison of
model predictions to available data. The statistical comparison of model predictions and the data would therefore be
part of the same system. The only computational route for us in NERL to make scalable computations and large data
sets available to all-comers is via cloud-hosted web applications. Desktop applications do not have the ability to
scale and are not reasonably downloadable when they contain regional level high resolution data; OEI/OSIM
interpretations of EPA guidance memos they wrote prevents us from serving data and running models on our NERL machines;
and we do not have anywhere near the resources that it would take to have OEI/NCC/etc stand such a system up for us &#8211;
nor do we feel they could provide a capable science solution or a sufficient front end even if we gave them a
significant portion of our research resources. Therefore, I think we need to be the first to fully leverage the
cloud within the Agency for model execution purposes. The CGI cloud contract is OEI approved and OEI is under a lot
of pressure from outside the agency to show that they are migrating applications to the cloud.</p>
<div class="section" id="objectives-of-model-calibration-activities-including-acceptance-criteria">
<h4>Objectives of model calibration activities, including acceptance criteria<a class="headerlink" href="#objectives-of-model-calibration-activities-including-acceptance-criteria" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="frequency-of-model-calibration-activities">
<h4>Frequency of model calibration activities<a class="headerlink" href="#frequency-of-model-calibration-activities" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="details-on-the-model-calibration-procedure">
<h4>Details on the model calibration procedure<a class="headerlink" href="#details-on-the-model-calibration-procedure" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="method-s-of-acquiring-input-data">
<h4>Method(s) of acquiring input data<a class="headerlink" href="#method-s-of-acquiring-input-data" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="types-of-output-generated-by-the-model-calibration">
<h4>Types of output generated by the model calibration<a class="headerlink" href="#types-of-output-generated-by-the-model-calibration" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="approach-to-characterize-uncertainty-e-g-sensitivity-analysis">
<h4>Approach to characterize uncertainty (e.g., sensitivity analysis)<a class="headerlink" href="#approach-to-characterize-uncertainty-e-g-sensitivity-analysis" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="corrective-action-to-be-taken-if-criteria-are-not-met">
<h4>Corrective action to be taken if criteria are not met<a class="headerlink" href="#corrective-action-to-be-taken-if-criteria-are-not-met" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="resources-and-responsibilities-for-calibrating-the-model">
<h4>Resources and responsibilities for calibrating the model<a class="headerlink" href="#resources-and-responsibilities-for-calibrating-the-model" title="Permalink to this headline">¶</a></h4>
<p>In addition to input data, government publications and publically available scientific liberature will be
considered for the development of the model. For example, the Agency’s Wildlife Exposure Factors Handbook will be
considered for estimating the dose to birds, mammals, terrestrial phase amphibians, reptiles, and terrestrial insects
via ingestion of water by determining the appropriate allometric equations for each taxa’s drinking water intake.</p>
</div>
<div class="section" id="analysis-of-model-output-relative-to-acceptance-criteria">
<h4>Analysis of model output relative to acceptance criteria<a class="headerlink" href="#analysis-of-model-output-relative-to-acceptance-criteria" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="non-direct-measurements-data-acquisition-requirements-b9">
<h3>Non-direct Measurements (Data Acquisition Requirements) (B9)<a class="headerlink" href="#non-direct-measurements-data-acquisition-requirements-b9" title="Permalink to this headline">¶</a></h3>
<p>The project will use secondary (non-direct) data from many sources and may generate large volumes of
modeled data during implementation. Some parameters are accepted as inputs from users who access the web application.
Other data sources undergo quality assurance analysis per their own project objectives. It is anticipated that all
secondary data will be acquired in electronic format. Acquisition of data will be documented in
electronic repositories.</p>
<div class="section" id="types-of-data-needed-for-implementing-a-project-that-are-obtained-from-non-measurement-sources-such-as-databases-literature-files">
<h4>Types of data needed for implementing a project that are obtained from non-measurement sources such as databases, literature files<a class="headerlink" href="#types-of-data-needed-for-implementing-a-project-that-are-obtained-from-non-measurement-sources-such-as-databases-literature-files" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="need-for-non-direct-measurements-intended-use-of-data">
<h4>Need for non-direct measurements, intended use of data<a class="headerlink" href="#need-for-non-direct-measurements-intended-use-of-data" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="method-s-of-identifying-and-acquiring-data">
<h4>Method(s) of identifying and acquiring data<a class="headerlink" href="#method-s-of-identifying-and-acquiring-data" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="method-of-determining-the-underlying-quality-of-the-data">
<h4>Method of determining the underlying quality of the data<a class="headerlink" href="#method-of-determining-the-underlying-quality-of-the-data" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="sops-and-field-or-lab-specific-deviations-associated-with-these-procedures">
<h4>SOPs and field or lab-specific deviations associated with these procedures<a class="headerlink" href="#sops-and-field-or-lab-specific-deviations-associated-with-these-procedures" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="acceptance-criteria-for-non-direct-measurements-such-as-completeness-representativeness-bias-precision-qualifying-data">
<h4>Acceptance criteria for non-direct measurements: such as completeness, representativeness, bias, precision, qualifying data<a class="headerlink" href="#acceptance-criteria-for-non-direct-measurements-such-as-completeness-representativeness-bias-precision-qualifying-data" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="data-management-and-hardware-software-configuration-b10">
<h3>Data Management and Hardware/Software Configuration (B10)<a class="headerlink" href="#data-management-and-hardware-software-configuration-b10" title="Permalink to this headline">¶</a></h3>
<p>This project will will acquire data from secondary sources, manipulate
secondary data to meet use requirements, generate data from model output, and create summary and
processed files for further statistical and analytical treatment. It is anticipated that the project will acquire
or generate little or no hardcopy data. The project will maintain a data management system that protects
integrity of the data received and generated throughout the project. This includes file management
systems, version control, archiving procedures, and quality assurance activities.</p>
<p>The project team will conduct all work and store all electronic files on a common ORD server at the
ERD/NERL Athens facility on the L drive. This server is backed up weekly
and maintained by EPA’s ITI contractors under the supervision of OSIM.</p>
<div class="section" id="data-management-element-b10a">
<h4>Data Management (Element B10a)<a class="headerlink" href="#data-management-element-b10a" title="Permalink to this headline">¶</a></h4>
<div class="section" id="any-data-forms-checklists-on-line-interactive-screens-used-in-the-modeling-process">
<h5>Any data forms, checklists, on-line interactive screens used in the modeling process<a class="headerlink" href="#any-data-forms-checklists-on-line-interactive-screens-used-in-the-modeling-process" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="any-graphics-developed-to-document-the-data-management-process-process-flow-diagrams-modeling-flow-charts-etc">
<h5>Any graphics developed to document the data management process (process flow diagrams, modeling flow charts, etc.)<a class="headerlink" href="#any-graphics-developed-to-document-the-data-management-process-process-flow-diagrams-modeling-flow-charts-etc" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="documentation-of-internal-checks-used-during-data-entry">
<h5>Documentation of internal checks used during data entry<a class="headerlink" href="#documentation-of-internal-checks-used-during-data-entry" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="data-calculations-and-analyses-that-should-to-be-highlighted-in-the-qa-project-plan">
<h5>Data calculations and analyses that should to be highlighted in the QA Project Plan<a class="headerlink" href="#data-calculations-and-analyses-that-should-to-be-highlighted-in-the-qa-project-plan" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-characterization-of-uncertainty-and-variability-in-the-model-results-e-g-summary-statistics-frequency-distributions-goodness-of-fit-tests">
<h5>Plans for characterization of uncertainty and variability in the model results (e.g., summary statistics, frequency distributions, goodness-of-fit tests)<a class="headerlink" href="#plans-for-characterization-of-uncertainty-and-variability-in-the-model-results-e-g-summary-statistics-frequency-distributions-goodness-of-fit-tests" title="Permalink to this headline">¶</a></h5>
</div>
</div>
<div class="section" id="hardware-software-configuration-element-b10b">
<h4>Hardware/software Configuration (Element B10b)<a class="headerlink" href="#hardware-software-configuration-element-b10b" title="Permalink to this headline">¶</a></h4>
<div class="section" id="list-of-equipment-hardware-and-software-that-will-be-used-on-the-project">
<h5>List of equipment, hardware, and software that will be used on the project<a class="headerlink" href="#list-of-equipment-hardware-and-software-that-will-be-used-on-the-project" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="description-of-performance-requirements">
<h5>Description of performance requirements<a class="headerlink" href="#description-of-performance-requirements" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="decisions-regarding-security-issues">
<h5>Decisions regarding security issues<a class="headerlink" href="#decisions-regarding-security-issues" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="decision-regarding-communication-issues">
<h5>Decision regarding communication issues<a class="headerlink" href="#decision-regarding-communication-issues" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="decisions-regarding-software-installation-issues">
<h5>Decisions regarding software installation issues<a class="headerlink" href="#decisions-regarding-software-installation-issues" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="decisions-regarding-response-time-issues">
<h5>Decisions regarding response time issues<a class="headerlink" href="#decisions-regarding-response-time-issues" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-requirements-documentation">
<h5>Plans for requirements documentation<a class="headerlink" href="#plans-for-requirements-documentation" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="coding-standards">
<h5>Coding standards<a class="headerlink" href="#coding-standards" title="Permalink to this headline">¶</a></h5>
<p>PEP-8</p>
</div>
<div class="section" id="testing-plans">
<h5>Testing plans<a class="headerlink" href="#testing-plans" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-data-dictionary-may-not-need-to-be-a-separate-document">
<h5>Plans for data dictionary (may not need to be a separate document)<a class="headerlink" href="#plans-for-data-dictionary-may-not-need-to-be-a-separate-document" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-a-users-manual">
<h5>Plans for a user’s manual<a class="headerlink" href="#plans-for-a-users-manual" title="Permalink to this headline">¶</a></h5>
<p>Online</p>
</div>
<div class="section" id="plans-for-a-maintenance-manual-explaining-software-logic-and-organization">
<h5>Plans for a maintenance manual (explaining software logic and organization)<a class="headerlink" href="#plans-for-a-maintenance-manual-explaining-software-logic-and-organization" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-source-code-for-the-ultimate-user-of-the-model-or-model-framework">
<h5>Plans for source code for the ultimate user of the model or model framework<a class="headerlink" href="#plans-for-source-code-for-the-ultimate-user-of-the-model-or-model-framework" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="configuration-management-plan-procedures-to-control-software-hardware-configuration-during-development-of-the-original-model-version">
<h5>Configuration management plan (procedures to control software/hardware configuration during development of the original model version)<a class="headerlink" href="#configuration-management-plan-procedures-to-control-software-hardware-configuration-during-development-of-the-original-model-version" title="Permalink to this headline">¶</a></h5>
</div>
</div>
</div>
</div>
<div class="section" id="group-c-assessment-and-oversight">
<h2>GROUP C: Assessment and Oversight<a class="headerlink" href="#group-c-assessment-and-oversight" title="Permalink to this headline">¶</a></h2>
<div class="section" id="assessment-and-response-actions-c1">
<h3>Assessment and Response Actions (C1)<a class="headerlink" href="#assessment-and-response-actions-c1" title="Permalink to this headline">¶</a></h3>
<p>The EPA Quality Assurance Manager will conduct a Technical Systems Audit (TSA) to ensure that this QAPP is being
followed during the execution of the research project. The research team is responsible for documenting the response
to any significant findings. Work conducted for this project will undergo ongoing technical review by personnel at
EPA/ORD/NERL/ERD who are implementing the project.</p>
<p>The project team leader will have responsibility for monitoring project activities and identifying or confirming any
quality problems. Any problems will be brought to the attention of the ORD Management Team and the ORD QA Team, who
will initiate corrective actions, document the nature of the problem, and ensure that the recommended corrective
action is carried out.</p>
<p>This QAPP describes processes for model sensitivity and uncertainty analysis (Section B7), data quality assessment
(Section B9), data management and error checking (Section B9) and model performance evaluations (section B7).
The project team will assess model sensitivity to parameters in calibration steps as well as in analysis steps
to understand model performance specific to modeling objectives. It has provisions for data validation and usability
(Section D)</p>
<p>Many of the technical problems that might occur can be solved on the spot by the technical staff, for example, by
modifying the technical approach or correcting errors or deficiencies in documentation. Immediate corrective
actions form part of normal operating procedures and are noted in records for the project. Problems that cannot be
solved in this way require more formalized, long-term corrective action. If quality problems that require attention
are identified, the QA Officers will determine whether attaining acceptable quality requires either short- or
long-term actions.</p>
<p>The Project Team Leader will perform surveillance activities to ensure that management and technical aspects are
being properly implemented according to the schedule and quality requirements specified in this QAPP. These
surveillance activities will include assessing how project milestones are achieved and documented, corrective
actions are implemented, budgets are adhered to, reviews are performed, and data are managed.</p>
<p>The technical systems assessment will include assessment of data collection activities, documentation, quality
checks, record management, and reporting.</p>
<p>Assessments of internal code validity and consistency of model structure will be ongoing. The first assessment will
occur when the model is initially structured and will emphasize internal code validation. At this point numerical
comparisons will be executed between model outputs and verified EPA reports. Any discrepancies will trigger an
in-depth review of the code. Intermediate computations will be compared against simple analytical cases in order
to localize the source of the error in the code. This will be conducted iteratively until the errors are found.
Discrepancies will be addressed through consideration of alternative scenarios and parameter values and adjustments
to model structure as indicated by the feedback. Revisions will be performed either by Tom Purucker or by a team
member under the close supervision of Tom Purucker. Documentation of QA procedures will occur when a draft paper is
being vetted for submission to an archival journal. If necessary based on the QA review, changes will be made to the
paper proposed for publication.</p>
<div class="section" id="hardware-software-assessments">
<h4>Hardware/Software Assessments<a class="headerlink" href="#hardware-software-assessments" title="Permalink to this headline">¶</a></h4>
<div class="section" id="plans-for-hardware-and-software-configuration-testing-if-appropriate">
<h5>Plans for hardware and software configuration testing, if appropriate<a class="headerlink" href="#plans-for-hardware-and-software-configuration-testing-if-appropriate" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-code-verification-tests">
<h5>Plans for code verification tests<a class="headerlink" href="#plans-for-code-verification-tests" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-internal-and-external-peer-reviews">
<h5>Plans for internal and external peer reviews<a class="headerlink" href="#plans-for-internal-and-external-peer-reviews" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-checking-for-programming-errors">
<h5>Plans for checking for programming errors<a class="headerlink" href="#plans-for-checking-for-programming-errors" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-checking-for-correct-insertion-of-model-equations">
<h5>Plans for checking for correct insertion of model equations<a class="headerlink" href="#plans-for-checking-for-correct-insertion-of-model-equations" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-checking-for-codes-linkage-to-analysis-of-uncertainty">
<h5>Plans for checking for code’s linkage to analysis of uncertainty<a class="headerlink" href="#plans-for-checking-for-codes-linkage-to-analysis-of-uncertainty" title="Permalink to this headline">¶</a></h5>
</div>
</div>
<div class="section" id="hardware-software-configuration-tests">
<h4>Hardware/Software Configuration Tests<a class="headerlink" href="#hardware-software-configuration-tests" title="Permalink to this headline">¶</a></h4>
<div class="section" id="plans-for-software-code-development-inspections">
<h5>Plans for software code development inspections<a class="headerlink" href="#plans-for-software-code-development-inspections" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-software-code-performance-testing">
<h5>Plans for software code performance testing<a class="headerlink" href="#plans-for-software-code-performance-testing" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-a-test-of-the-model-framework">
<h5>Plans for a test of the model framework<a class="headerlink" href="#plans-for-a-test-of-the-model-framework" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-integration-tests-check-computational-and-transfer-interfaces-between-modules">
<h5>Plans for integration tests (check computational and transfer interfaces between modules)<a class="headerlink" href="#plans-for-integration-tests-check-computational-and-transfer-interfaces-between-modules" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-regression-tests">
<h5>Plans for regression tests<a class="headerlink" href="#plans-for-regression-tests" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-stress-testing-of-complex-models-to-ensure-that-maximum-load-during-peak-usage-does-not-exceed-limits-of-the-system">
<h5>Plans for stress testing of complex models (to ensure that maximum load during peak usage does not exceed limits of the system)<a class="headerlink" href="#plans-for-stress-testing-of-complex-models-to-ensure-that-maximum-load-during-peak-usage-does-not-exceed-limits-of-the-system" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-acceptance-testing-contractually-required-testing-needed-before-a-new-model-or-model-application-is-accepted-by-the-customer-and-final-payment-is-made">
<h5>Plans for acceptance testing (contractually-required testing needed before a new model or model application is accepted by the customer and final payment is made)<a class="headerlink" href="#plans-for-acceptance-testing-contractually-required-testing-needed-before-a-new-model-or-model-application-is-accepted-by-the-customer-and-final-payment-is-made" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-beta-testing-of-pre-release-hardware-software-recording-of-anomalies">
<h5>Plans for beta testing of pre-release hardware/software, recording of anomalies<a class="headerlink" href="#plans-for-beta-testing-of-pre-release-hardware-software-recording-of-anomalies" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="id35">
<h5>Plans for checking for programming errors<a class="headerlink" href="#id35" title="Permalink to this headline">¶</a></h5>
</div>
</div>
<div class="section" id="plans-for-science-and-product-peer-review">
<h4>Plans for science and product peer review<a class="headerlink" href="#plans-for-science-and-product-peer-review" title="Permalink to this headline">¶</a></h4>
<div class="section" id="theoretical-basis-for-the-model">
<h5>Theoretical basis for the model<a class="headerlink" href="#theoretical-basis-for-the-model" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="mathematical-model-structure">
<h5>Mathematical model structure<a class="headerlink" href="#mathematical-model-structure" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="model-algorithms">
<h5>Model algorithms<a class="headerlink" href="#model-algorithms" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="model-predictions">
<h5>Model predictions<a class="headerlink" href="#model-predictions" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="model-calibration">
<h5>Model calibration<a class="headerlink" href="#model-calibration" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-data-quality-assessment">
<h5>Plans for data quality assessment<a class="headerlink" href="#plans-for-data-quality-assessment" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="plans-for-peer-review-of-final-technical-product">
<h5>Plans for peer review of final technical product<a class="headerlink" href="#plans-for-peer-review-of-final-technical-product" title="Permalink to this headline">¶</a></h5>
</div>
</div>
</div>
<div class="section" id="reports-to-management-c2">
<h3>Reports to Management (C2)<a class="headerlink" href="#reports-to-management-c2" title="Permalink to this headline">¶</a></h3>
<div class="section" id="project-reporting-schedule">
<h4>Project reporting schedule<a class="headerlink" href="#project-reporting-schedule" title="Permalink to this headline">¶</a></h4>
<p>This QAPP will be distributed to the ubertool project team and stored on the G-drive in the ubertool folder. The
model, user guidance, and technical documentation will be stored on the XXX drive XXXX folder. The model and
technical documentation will also be made available on the ubertool web page. Backup copies of all the development
documentation will be kept by the project lead.</p>
<p>Periodic updates/progress reports will be given to ORD management, the XXXX and end users as needed to discuss the
progress of the project. A written QC, technical assessments, and documentation will be made available to interested
parties. Management will be kept informed of the project’s progress through the managerial advisor and/or periodic
briefings.</p>
<p>Any identified errors, deficiencies, and anomalies will be documented and reported to the team. If needed, an error
analysis will be performed and the model processes will be reviewed and/or modified.</p>
</div>
<div class="section" id="frequency-content-and-distribution-of-reports">
<h4>Frequency, content, and distribution of reports<a class="headerlink" href="#frequency-content-and-distribution-of-reports" title="Permalink to this headline">¶</a></h4>
<p>Models will be published as publicly consumable APIs. APIs function by linking different information sources in a
shared network of data and services. This ensures mutually beneficial sharing of authoritative data sets, services,
and infrastructures within and outside of the Agency in a controllable manner. EPA chemical exposure and effects
models have been developed at different times and based on different underlying technologies over the last 40 years,
there are a number of legacy codes that underlay important scientific processes. The resulting set of Agency models
differ in programming languages, deployment processes, operating systems, and other technical dependencies. These
structural differences have hindered their accessibility, transparency, interoperability and scientific use.
Modern API development that relies on REST services, remote procedure calls and cloud server infrastructures resolves
these difference and enhance service and model reuse by regulatory and scientific communities. This approach addresses
scientific web services security in a federally approved manner, provides “web analytics” &#8211; offering a supplement to
journal metrics in documenting the impact of EPA models, and makes the algorithms more “discoverable” &#8211; thereby
increasing their use.</p>
<p>Of significant scientific importance is that providing an API and the underlying web services via a cloud computing
environment provides computational scaling abilities not currently available for chemical modeling on the desktop by
leveraging a cloud computing infrastructure (CGI). The federal government has mandated a “Cloud First” strategy to
help federal agencies provide highly reliable, innovative services quickly and efficiently despite resource constraints.
Cloud computing allows for the pooling of computer servers into an integrated system even if those servers are running
different operating systems and applications with different technological dependencies. Computational power is
increased or decreased depending on real-time workload requirements, and the system is continually reconfigured to
meet new types of workloads. This scalability allows for other scientific programmers to leverage the tools, whether
they are scientific applications of the models themselves, providing dashboard services, or embedding them within
more complex regulatory workflows (e.g., ubertool). Cloud-based scientific applications include Monte Carlo
applications to examine parameter sensitivity and model uncertainty, frequentist and Bayesian approaches for model
calibration and selection/weighting, distributed spatial scaling of science algorithms, and/or data intensive
algorithms run at high temporal resolution.</p>
<p>Cloud-based API construction can enhance regulatory transparency, increase the impact of existing Agency science,
and greatly accelerate the translation of new science and algorithms to regulatory application. The EPA has the
opportunity to be in the vanguard due to the significant set of science models they “own”, the existing cloud
infrastructure, and significant progress already made for FIFRA/ESA ecological models (front end, back end).
Similar opportunities exist for human health models and ecological models for non-FIFRA/ESA applications.</p>
</div>
<div class="section" id="deviations-from-approved-qa-project-plan">
<h4>Deviations from approved QA Project Plan<a class="headerlink" href="#deviations-from-approved-qa-project-plan" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="need-for-response-actions-to-correct-deviations">
<h4>Need for response actions to correct deviations<a class="headerlink" href="#need-for-response-actions-to-correct-deviations" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="potential-uncertainties-in-decisions-based-on-input-data-and-model-limitations">
<h4>Potential uncertainties in decisions based on input data and model limitations<a class="headerlink" href="#potential-uncertainties-in-decisions-based-on-input-data-and-model-limitations" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="data-quality-assessment-findings">
<h4>Data Quality Assessment findings<a class="headerlink" href="#data-quality-assessment-findings" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="section" id="group-d-data-validation-and-usability">
<h2>GROUP D: Data Validation and Usability<a class="headerlink" href="#group-d-data-validation-and-usability" title="Permalink to this headline">¶</a></h2>
<p>This project uses well-known ecological assessment models to estimate risk that have a history of extensive use by
public agencies and universities and
documentation in peer-reviewed literature. The modeling requires input data that must be acquired
from federal, state, and local authorities, as well as private entities. The quality of data used for and
generated during modeling will be reviewed and verified at multiple levels by project technical staff and
QA officers, as described in detail in other sections.</p>
<div class="section" id="departures-from-validation-criteria-d1">
<h3>Departures from Validation Criteria (D1)<a class="headerlink" href="#departures-from-validation-criteria-d1" title="Permalink to this headline">¶</a></h3>
<p>To evaluate the correctness of programmed models, a quality control/quality assurance (QA/QC) page is created, which
validates models’ inputs and outputs towards given sample calculations. The sources of sample calculations come from
verified EPA reports. Any discrepancies will trigger an in-depth review of the code. Intermediate computations will
be compared against simple analytical cases in order to localize the source of the error in the code. Discrepancies
will be addressed through consideration of alternative scenarios and parameter values and adjustments to model
structure as indicated by the feedback.</p>
<div class="section" id="criteria-used-to-review-and-validate-accept-reject-or-qualify-model-components-such-as-theory-mathematical-procedures-code-and-calibration-convergence-criteria-etc">
<h4>Criteria used to review and validate (accept, reject, or qualify) model components such as theory, mathematical procedures, code, and calibration (convergence criteria, etc.)<a class="headerlink" href="#criteria-used-to-review-and-validate-accept-reject-or-qualify-model-components-such-as-theory-mathematical-procedures-code-and-calibration-convergence-criteria-etc" title="Permalink to this headline">¶</a></h4>
<p>Model-dependent.</p>
</div>
<div class="section" id="criteria-used-to-review-and-validate-input-data">
<h4>Criteria used to review and validate input data<a class="headerlink" href="#criteria-used-to-review-and-validate-input-data" title="Permalink to this headline">¶</a></h4>
<p>Input data will be obtained from verified EPA reports, which legitimizes the sources. Thus data review, verification,
and validation will focus on the consistency of the input data used for calculations and modeling. As a result, an
input table (Figure below) is present on the QA/QC page, including values used in the computation. Numerical
comparisons between QA/QC input table and verified EPA reports will be executed. Any deviations will raise the
check of the code and will be documented in writing and reviewed by the ORD Management team and the ORD Quality team.</p>
<p>Data review, verification, and validation will focus on acceptability of the input data used for calculations
and modeling. All original and modified data files will be reviewed for input, handling, and calculation
errors. Any issues identified through this review process will be evaluated and, if necessary, data will be
corrected and analysis carried out using corrected data.</p>
<p>Deviations from the approved QAPP could occur as the project proceeds. The need for adjustments may
arise based on data validation and quality assurance checks, outcomes of model initialization and
calibration steps, scenario development, and so on. Deviations will be documented in writing and
reviewed by the ORD Management Team and the ORD Quality Team. The QAPP will be revised
accordingly and recirculated for Quality Assurance review and approval.</p>
<p>Figure #. User input table from the QA/QC page</p>
<p>To evaluate the correctness of programmed models, a quality control/quality assurance (QA/QC) page is created, which
validates models’ inputs and outputs towards given sample calculations. The sources of sample calculations come
from verified EPA reports. Any discrepancies will trigger an in-depth review of the code. Intermediate computations
will be compared against simple analytical cases in order to localize the source of the error in the code.
Discrepancies will be addressed through consideration of alternative scenarios and parameter values and adjustments
to model structure as indicated by the feedback.</p>
<p>Input data will be obtained from verified EPA reports, which legitimizes the sources. Thus data review, verification,
and validation will focus on the consistency of the input data used for calculations and modeling. As a result, an
input table (Figure below) is present on the QA/QC page, including values used in the computation. Numerical
comparisons between QA/QC input table and verified EPA reports will be executed. Any deviations will raise the
check of the code and will be documented in writing and reviewed by the ORD Management team and the ORD Quality team</p>
</div>
<div class="section" id="criteria-used-to-test-model-performance">
<h4>Criteria used to test model performance<a class="headerlink" href="#criteria-used-to-test-model-performance" title="Permalink to this headline">¶</a></h4>
<p>Model performance is checked through the ‘Batch’ mode, which sequentially calculates scenarios provided in the
template. Two testing criterion are considered here: 1. repeat the same scenarios in the template (e.g. 10 times),
and check the consistency of model inputs and outputs among 10 scenarios; 2. list a large number of scenarios
(e.g. 10,000) and estimate the time consumed during the computation.</p>
</div>
<div class="section" id="criteria-used-to-review-or-validate-model-outputs">
<h4>Criteria used to review or validate model outputs<a class="headerlink" href="#criteria-used-to-review-or-validate-model-outputs" title="Permalink to this headline">¶</a></h4>
<p>The integrity of model output data will be verified and validated by project technical staff. Reviews may
include a thorough evaluation of content and/or a “spot-check” of calculated between output tables
(Figure below) in the QA/QC page and verified EPA reports. Should a review identify an aberration, the reviewer
will notify those responsible for taking corrective actions. The QA officers will be notified if corrective action
is potentially required. Evaluation of whether model components and their outputs are correct will be an ongoing process
for QA personnel during the model calibration and validation stage of the project.
In-progress assessments of validation issues will be discussed between a team including both technical and
QA representatives from EPA. The results of performing evaluations will be logged and integrated into the project
documentation at the conclusion of the project, as well any corrective actions that were implemented.</p>
<p>Evaluation of whether model components and their outputs are satisfying the project objectives will be an ongoing
process for QA personnel during model calibration and validation stages of the project. In-progress
assessments of validation issues will be discussed by a team including technical and QA representatives
from EPA.</p>
<blockquote>
<div>Figure #. Output tables from the QA/QC page</div></blockquote>
</div>
</div>
<div class="section" id="validation-methods-d2">
<h3>Validation Methods (D2)<a class="headerlink" href="#validation-methods-d2" title="Permalink to this headline">¶</a></h3>
<div class="section" id="methods-for-review-of-model-components-such-as-theory-mathematical-procedures-code-and-calibration-peer-review-etc">
<h4>Methods for review of model components such as theory, mathematical procedures, code, and calibration (peer review, etc.)<a class="headerlink" href="#methods-for-review-of-model-components-such-as-theory-mathematical-procedures-code-and-calibration-peer-review-etc" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="methods-for-review-of-input-data">
<h4>Methods for review of input data<a class="headerlink" href="#methods-for-review-of-input-data" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="methods-for-review-of-model-performance-tests">
<h4>Methods for review of model performance tests<a class="headerlink" href="#methods-for-review-of-model-performance-tests" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="methods-for-assessment-of-model-output-and-usability">
<h4>Methods for assessment of model output and usability<a class="headerlink" href="#methods-for-assessment-of-model-output-and-usability" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="reconciliation-with-user-requirements-d3">
<h3>Reconciliation with User Requirements (D3)<a class="headerlink" href="#reconciliation-with-user-requirements-d3" title="Permalink to this headline">¶</a></h3>
<p>The objective of the project is to assess..</p>
<div class="section" id="discussion-of-project-or-task-results">
<h4>Discussion of project or task results<a class="headerlink" href="#discussion-of-project-or-task-results" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="list-of-departures-from-assumptions-set-in-the-planning-phase-of-the-model">
<h4>List of departures from assumptions set in the planning phase of the model<a class="headerlink" href="#list-of-departures-from-assumptions-set-in-the-planning-phase-of-the-model" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="report-on-limitations-on-use-of-output-data-for-decision-makers-or-users">
<h4>Report on limitations on use of output data for decision makers or users<a class="headerlink" href="#report-on-limitations-on-use-of-output-data-for-decision-makers-or-users" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="section" id="references">
<h2>REFERENCES<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>Apandi, T., 2009 Extreme Programming Pocket Guide. O’Reilly Media, Sebastopol, CA.</p>
<p>Helms, J.C., 2013. Web-Based Application Quality Assurance Testing. Accessed at
<a class="reference external" href="http://ils.indiana.edu/faculty/hrosenba/www/S512/pdf/helm_web-qa.pdf">http://ils.indiana.edu/faculty/hrosenba/www/S512/pdf/helm_web-qa.pdf</a> on 9/5/2013.</p>
<p>USEPA, 2002. Guidance for Quality Assurance Project Plans for Modeling. EPA QA/G-5M.</p>
<p>USEPA. 2004. Overview of the Ecological Risk Assessment Process in the Office of Pesticide Programs. U.S.
Environmental Protection Agency, Office of Prevention, Pesticides and Toxic Substances, Office of Pesticide Programs,
Washington DC. 100 pp. January 23, 2004.</p>
<p>USFWS and National Marine Fisheries Service (NMFS). 1998. Endangered Species Consultation Handbook:
Procedures for Conducting Consultation and Conference Activities Under Section 7 of the Endangered Species Act.
Final Draft. March 1998.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">ubertool Quality Assurance Project Plan</a><ul>
<li><a class="reference internal" href="#project-management">Project Management</a><ul>
<li><a class="reference internal" href="#title-and-approval-sheet">Title and Approval Sheet</a><ul>
<li><a class="reference internal" href="#title-of-qa-project-plan">Title of QA Project Plan</a></li>
<li><a class="reference internal" href="#revision-number-of-qa-project-plan">Revision number of QA Project Plan</a></li>
<li><a class="reference internal" href="#effective-data-of-qa-project-plan">Effective Data of QA Project Plan</a></li>
<li><a class="reference internal" href="#names-of-all-organizations-involved-in-the-modeling-project">Names of all organizations involved in the modeling project</a></li>
<li><a class="reference internal" href="#names-of-all-key-project-officials-with-space-for-dated-signatures">Names of all key project officials, with space for dated signatures</a></li>
</ul>
</li>
<li><a class="reference internal" href="#table-of-contents-and-document-control-format">Table of Contents and Document Control Format</a></li>
<li><a class="reference internal" href="#distribution-list-a3">Distribution List (A3)</a></li>
<li><a class="reference internal" href="#project-task-organization-a4">Project/Task Organization (A4)</a></li>
<li><a class="reference internal" href="#problem-definition-background-a5">Problem Definition/Background (A5)</a><ul>
<li><a class="reference internal" href="#goals-and-objectives-of-this-project-that-will-address-this-problem">Goals and objectives of this project that will address this problem</a></li>
<li><a class="reference internal" href="#definition-of-the-population-the-problem-targets-and-what-measures-within-this-population-the-problem-addresses">Definition of the population the problem targets and what measures within this population the problem addresses</a></li>
<li><a class="reference internal" href="#reason-the-project-includes-a-modeling-approach-to-address-the-problem-is-it-a-new-predictive-tool">Reason the project includes a modeling approach to address the problem (is it a new predictive tool?)</a></li>
<li><a class="reference internal" href="#types-of-decisions-that-may-be-made-as-a-result-of-this-project">Types of decisions that may be made as a result of this project</a></li>
<li><a class="reference internal" href="#any-other-types-of-problems-that-the-project-may-address">Any other types of problems that the project may address</a></li>
<li><a class="reference internal" href="#background-information-on-the-problem">Background information on the problem</a></li>
<li><a class="reference internal" href="#reasons-the-project-is-important-how-it-supports-other-existing-research-programs-or-regulations">Reasons the project is important, how it supports other existing research, programs, or regulations</a></li>
<li><a class="reference internal" href="#conflicts-or-uncertainties-that-will-be-resolved-by-this-project">Conflicts or uncertainties that will be resolved by this project</a></li>
<li><a class="reference internal" href="#reasons-one-model-is-determined-to-be-better-than-another-for-this-application">Reasons one model is determined to be better than another for this application</a></li>
</ul>
</li>
<li><a class="reference internal" href="#project-task-description-and-schedule-a6">Project/Task Description and Schedule (A6)</a><ul>
<li><a class="reference internal" href="#summary-of-all-work-to-be-performed-products-to-be-produced-and-the-schedule-for-implementation">Summary of all work to be performed, products to be produced, and the schedule for implementation</a></li>
<li><a class="reference internal" href="#list-of-products-deliverables-and-milestones-to-be-completed-in-the-various-stages-of-the-project">List of products, deliverables, and milestones to be completed in the various stages of the project</a></li>
<li><a class="reference internal" href="#schedule-of-anticipated-start-and-completion-dates-for-the-milestones-and-deliverables-and-persons-responsible-for-each">Schedule of anticipated start and completion dates for the milestones and deliverables, and persons responsible for each</a></li>
</ul>
</li>
<li><a class="reference internal" href="#quality-objectives-and-criteria-for-model-inputs-outputs-a7">Quality Objectives and Criteria for Model Inputs/Outputs (A7)</a><ul>
<li><a class="reference internal" href="#project-data-quality-objectives-dqos-performance-criteria-and-acceptance-criteria">Project data quality objectives (DQOs), performance criteria, and acceptance criteria</a></li>
<li><a class="reference internal" href="#description-of-task-that-needs-to-be-addressed-and-the-intended-uses-of-the-output-of-the-modeling-project-to-achieve-the-task">Description of task that needs to be addressed and the intended uses of the output of the modeling project to achieve the task</a><ul>
<li><a class="reference internal" href="#ecological-models">Ecological Models</a></li>
<li><a class="reference internal" href="#database-sources">Database Sources</a></li>
</ul>
</li>
<li><a class="reference internal" href="#list-of-requirements-associated-with-the-hardware-software-configuration-for-those-studies-involving-software-evaluation">List of requirements associated with the hardware/software configuration for those studies involving software evaluation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#special-training-requirements-certification-a8">Special Training Requirements/Certification (A8)</a><ul>
<li><a class="reference internal" href="#types-of-required-training-and-certification-needed-by-the-project-team">Types of required training and certification needed by the project team</a></li>
<li><a class="reference internal" href="#plan-for-obtaining-training-and-or-certification">Plan for obtaining training and/or certification</a></li>
<li><a class="reference internal" href="#documentation-of-training-and-or-certification">Documentation of training and/or certification</a></li>
</ul>
</li>
<li><a class="reference internal" href="#documentation-and-records-a9">Documentation and Records (A9)</a><ul>
<li><a class="reference internal" href="#description-of-information-to-be-included-in-reports">Description of information to be included in reports</a></li>
<li><a class="reference internal" href="#proper-document-control-and-distribution-procedures">Proper document control and distribution procedures</a></li>
<li><a class="reference internal" href="#details-on-document-storage">Details on document storage</a></li>
<li><a class="reference internal" href="#backup-plan-for-records-stored-electronically">Backup plan for records stored electronically</a></li>
<li><a class="reference internal" href="#description-of-the-change-control-process-who-approves-changes-etc">Description of the change control process (who approves changes, etc.)</a></li>
<li><a class="reference internal" href="#length-of-retention-periods-for-each-record">Length of retention periods for each record</a></li>
<li><a class="reference internal" href="#data-assessment-reports-interim-project-progress-reports">Data assessment reports, interim project progress reports</a></li>
<li><a class="reference internal" href="#model-science-formulation-report-peer-review-reports">Model science formulation report, peer review reports</a></li>
<li><a class="reference internal" href="#model-assessment-reports-interim-project-progress-reports">Model assessment reports, interim project progress reports</a></li>
<li><a class="reference internal" href="#code-standards-code-auditing-and-testing-reports-interim-project-progress-reports">Code standards, code auditing and testing reports, interim project progress reports</a></li>
<li><a class="reference internal" href="#model-calibration-report">Model calibration report</a></li>
<li><a class="reference internal" href="#model-evaluation-records-how-well-does-the-model-report-variability-and-uncertainty-in-its-output">Model evaluation records (How well does the model report variability and uncertainty in its output?)</a></li>
<li><a class="reference internal" href="#users-manual">User’s manual</a></li>
<li><a class="reference internal" href="#configuration-management-after-production-version-and-code-maintenance-e-g-or-software-internal-documentation-of-logic-and-structure-manuals">Configuration management (after production version) and code maintenance (e.g., or software internal documentation of logic and structure) manuals</a></li>
<li><a class="reference internal" href="#licensing-issues">Licensing Issues</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#group-b-measurement-and-data-acquisition">GROUP B: Measurement and Data Acquisition</a><ul>
<li><a class="reference internal" href="#sampling-process-design-b1">Sampling Process Design (B1)</a></li>
<li><a class="reference internal" href="#sampling-methods-b2">Sampling Methods (B2)</a></li>
<li><a class="reference internal" href="#sampling-handling-and-custody-b3">Sampling Handling and Custody (B3)</a></li>
<li><a class="reference internal" href="#analytical-methods-b4">Analytical Methods (B4)</a></li>
<li><a class="reference internal" href="#quality-control-b5">Quality Control (B5)</a></li>
<li><a class="reference internal" href="#instrument-equipment-testing-inspection-and-maintenance-b6">Instrument/Equipment Testing, Inspection, and Maintenance (B6)</a></li>
<li><a class="reference internal" href="#calibration-b7">Calibration (B7)</a><ul>
<li><a class="reference internal" href="#objectives-of-model-calibration-activities-including-acceptance-criteria">Objectives of model calibration activities, including acceptance criteria</a></li>
<li><a class="reference internal" href="#frequency-of-model-calibration-activities">Frequency of model calibration activities</a></li>
<li><a class="reference internal" href="#details-on-the-model-calibration-procedure">Details on the model calibration procedure</a></li>
<li><a class="reference internal" href="#method-s-of-acquiring-input-data">Method(s) of acquiring input data</a></li>
<li><a class="reference internal" href="#types-of-output-generated-by-the-model-calibration">Types of output generated by the model calibration</a></li>
<li><a class="reference internal" href="#approach-to-characterize-uncertainty-e-g-sensitivity-analysis">Approach to characterize uncertainty (e.g., sensitivity analysis)</a></li>
<li><a class="reference internal" href="#corrective-action-to-be-taken-if-criteria-are-not-met">Corrective action to be taken if criteria are not met</a></li>
<li><a class="reference internal" href="#resources-and-responsibilities-for-calibrating-the-model">Resources and responsibilities for calibrating the model</a></li>
<li><a class="reference internal" href="#analysis-of-model-output-relative-to-acceptance-criteria">Analysis of model output relative to acceptance criteria</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-direct-measurements-data-acquisition-requirements-b9">Non-direct Measurements (Data Acquisition Requirements) (B9)</a><ul>
<li><a class="reference internal" href="#types-of-data-needed-for-implementing-a-project-that-are-obtained-from-non-measurement-sources-such-as-databases-literature-files">Types of data needed for implementing a project that are obtained from non-measurement sources such as databases, literature files</a></li>
<li><a class="reference internal" href="#need-for-non-direct-measurements-intended-use-of-data">Need for non-direct measurements, intended use of data</a></li>
<li><a class="reference internal" href="#method-s-of-identifying-and-acquiring-data">Method(s) of identifying and acquiring data</a></li>
<li><a class="reference internal" href="#method-of-determining-the-underlying-quality-of-the-data">Method of determining the underlying quality of the data</a></li>
<li><a class="reference internal" href="#sops-and-field-or-lab-specific-deviations-associated-with-these-procedures">SOPs and field or lab-specific deviations associated with these procedures</a></li>
<li><a class="reference internal" href="#acceptance-criteria-for-non-direct-measurements-such-as-completeness-representativeness-bias-precision-qualifying-data">Acceptance criteria for non-direct measurements: such as completeness, representativeness, bias, precision, qualifying data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-management-and-hardware-software-configuration-b10">Data Management and Hardware/Software Configuration (B10)</a><ul>
<li><a class="reference internal" href="#data-management-element-b10a">Data Management (Element B10a)</a><ul>
<li><a class="reference internal" href="#any-data-forms-checklists-on-line-interactive-screens-used-in-the-modeling-process">Any data forms, checklists, on-line interactive screens used in the modeling process</a></li>
<li><a class="reference internal" href="#any-graphics-developed-to-document-the-data-management-process-process-flow-diagrams-modeling-flow-charts-etc">Any graphics developed to document the data management process (process flow diagrams, modeling flow charts, etc.)</a></li>
<li><a class="reference internal" href="#documentation-of-internal-checks-used-during-data-entry">Documentation of internal checks used during data entry</a></li>
<li><a class="reference internal" href="#data-calculations-and-analyses-that-should-to-be-highlighted-in-the-qa-project-plan">Data calculations and analyses that should to be highlighted in the QA Project Plan</a></li>
<li><a class="reference internal" href="#plans-for-characterization-of-uncertainty-and-variability-in-the-model-results-e-g-summary-statistics-frequency-distributions-goodness-of-fit-tests">Plans for characterization of uncertainty and variability in the model results (e.g., summary statistics, frequency distributions, goodness-of-fit tests)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hardware-software-configuration-element-b10b">Hardware/software Configuration (Element B10b)</a><ul>
<li><a class="reference internal" href="#list-of-equipment-hardware-and-software-that-will-be-used-on-the-project">List of equipment, hardware, and software that will be used on the project</a></li>
<li><a class="reference internal" href="#description-of-performance-requirements">Description of performance requirements</a></li>
<li><a class="reference internal" href="#decisions-regarding-security-issues">Decisions regarding security issues</a></li>
<li><a class="reference internal" href="#decision-regarding-communication-issues">Decision regarding communication issues</a></li>
<li><a class="reference internal" href="#decisions-regarding-software-installation-issues">Decisions regarding software installation issues</a></li>
<li><a class="reference internal" href="#decisions-regarding-response-time-issues">Decisions regarding response time issues</a></li>
<li><a class="reference internal" href="#plans-for-requirements-documentation">Plans for requirements documentation</a></li>
<li><a class="reference internal" href="#coding-standards">Coding standards</a></li>
<li><a class="reference internal" href="#testing-plans">Testing plans</a></li>
<li><a class="reference internal" href="#plans-for-data-dictionary-may-not-need-to-be-a-separate-document">Plans for data dictionary (may not need to be a separate document)</a></li>
<li><a class="reference internal" href="#plans-for-a-users-manual">Plans for a user’s manual</a></li>
<li><a class="reference internal" href="#plans-for-a-maintenance-manual-explaining-software-logic-and-organization">Plans for a maintenance manual (explaining software logic and organization)</a></li>
<li><a class="reference internal" href="#plans-for-source-code-for-the-ultimate-user-of-the-model-or-model-framework">Plans for source code for the ultimate user of the model or model framework</a></li>
<li><a class="reference internal" href="#configuration-management-plan-procedures-to-control-software-hardware-configuration-during-development-of-the-original-model-version">Configuration management plan (procedures to control software/hardware configuration during development of the original model version)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#group-c-assessment-and-oversight">GROUP C: Assessment and Oversight</a><ul>
<li><a class="reference internal" href="#assessment-and-response-actions-c1">Assessment and Response Actions (C1)</a><ul>
<li><a class="reference internal" href="#hardware-software-assessments">Hardware/Software Assessments</a><ul>
<li><a class="reference internal" href="#plans-for-hardware-and-software-configuration-testing-if-appropriate">Plans for hardware and software configuration testing, if appropriate</a></li>
<li><a class="reference internal" href="#plans-for-code-verification-tests">Plans for code verification tests</a></li>
<li><a class="reference internal" href="#plans-for-internal-and-external-peer-reviews">Plans for internal and external peer reviews</a></li>
<li><a class="reference internal" href="#plans-for-checking-for-programming-errors">Plans for checking for programming errors</a></li>
<li><a class="reference internal" href="#plans-for-checking-for-correct-insertion-of-model-equations">Plans for checking for correct insertion of model equations</a></li>
<li><a class="reference internal" href="#plans-for-checking-for-codes-linkage-to-analysis-of-uncertainty">Plans for checking for code’s linkage to analysis of uncertainty</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hardware-software-configuration-tests">Hardware/Software Configuration Tests</a><ul>
<li><a class="reference internal" href="#plans-for-software-code-development-inspections">Plans for software code development inspections</a></li>
<li><a class="reference internal" href="#plans-for-software-code-performance-testing">Plans for software code performance testing</a></li>
<li><a class="reference internal" href="#plans-for-a-test-of-the-model-framework">Plans for a test of the model framework</a></li>
<li><a class="reference internal" href="#plans-for-integration-tests-check-computational-and-transfer-interfaces-between-modules">Plans for integration tests (check computational and transfer interfaces between modules)</a></li>
<li><a class="reference internal" href="#plans-for-regression-tests">Plans for regression tests</a></li>
<li><a class="reference internal" href="#plans-for-stress-testing-of-complex-models-to-ensure-that-maximum-load-during-peak-usage-does-not-exceed-limits-of-the-system">Plans for stress testing of complex models (to ensure that maximum load during peak usage does not exceed limits of the system)</a></li>
<li><a class="reference internal" href="#plans-for-acceptance-testing-contractually-required-testing-needed-before-a-new-model-or-model-application-is-accepted-by-the-customer-and-final-payment-is-made">Plans for acceptance testing (contractually-required testing needed before a new model or model application is accepted by the customer and final payment is made)</a></li>
<li><a class="reference internal" href="#plans-for-beta-testing-of-pre-release-hardware-software-recording-of-anomalies">Plans for beta testing of pre-release hardware/software, recording of anomalies</a></li>
<li><a class="reference internal" href="#id35">Plans for checking for programming errors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#plans-for-science-and-product-peer-review">Plans for science and product peer review</a><ul>
<li><a class="reference internal" href="#theoretical-basis-for-the-model">Theoretical basis for the model</a></li>
<li><a class="reference internal" href="#mathematical-model-structure">Mathematical model structure</a></li>
<li><a class="reference internal" href="#model-algorithms">Model algorithms</a></li>
<li><a class="reference internal" href="#model-predictions">Model predictions</a></li>
<li><a class="reference internal" href="#model-calibration">Model calibration</a></li>
<li><a class="reference internal" href="#plans-for-data-quality-assessment">Plans for data quality assessment</a></li>
<li><a class="reference internal" href="#plans-for-peer-review-of-final-technical-product">Plans for peer review of final technical product</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#reports-to-management-c2">Reports to Management (C2)</a><ul>
<li><a class="reference internal" href="#project-reporting-schedule">Project reporting schedule</a></li>
<li><a class="reference internal" href="#frequency-content-and-distribution-of-reports">Frequency, content, and distribution of reports</a></li>
<li><a class="reference internal" href="#deviations-from-approved-qa-project-plan">Deviations from approved QA Project Plan</a></li>
<li><a class="reference internal" href="#need-for-response-actions-to-correct-deviations">Need for response actions to correct deviations</a></li>
<li><a class="reference internal" href="#potential-uncertainties-in-decisions-based-on-input-data-and-model-limitations">Potential uncertainties in decisions based on input data and model limitations</a></li>
<li><a class="reference internal" href="#data-quality-assessment-findings">Data Quality Assessment findings</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#group-d-data-validation-and-usability">GROUP D: Data Validation and Usability</a><ul>
<li><a class="reference internal" href="#departures-from-validation-criteria-d1">Departures from Validation Criteria (D1)</a><ul>
<li><a class="reference internal" href="#criteria-used-to-review-and-validate-accept-reject-or-qualify-model-components-such-as-theory-mathematical-procedures-code-and-calibration-convergence-criteria-etc">Criteria used to review and validate (accept, reject, or qualify) model components such as theory, mathematical procedures, code, and calibration (convergence criteria, etc.)</a></li>
<li><a class="reference internal" href="#criteria-used-to-review-and-validate-input-data">Criteria used to review and validate input data</a></li>
<li><a class="reference internal" href="#criteria-used-to-test-model-performance">Criteria used to test model performance</a></li>
<li><a class="reference internal" href="#criteria-used-to-review-or-validate-model-outputs">Criteria used to review or validate model outputs</a></li>
</ul>
</li>
<li><a class="reference internal" href="#validation-methods-d2">Validation Methods (D2)</a><ul>
<li><a class="reference internal" href="#methods-for-review-of-model-components-such-as-theory-mathematical-procedures-code-and-calibration-peer-review-etc">Methods for review of model components such as theory, mathematical procedures, code, and calibration (peer review, etc.)</a></li>
<li><a class="reference internal" href="#methods-for-review-of-input-data">Methods for review of input data</a></li>
<li><a class="reference internal" href="#methods-for-review-of-model-performance-tests">Methods for review of model performance tests</a></li>
<li><a class="reference internal" href="#methods-for-assessment-of-model-output-and-usability">Methods for assessment of model output and usability</a></li>
</ul>
</li>
<li><a class="reference internal" href="#reconciliation-with-user-requirements-d3">Reconciliation with User Requirements (D3)</a><ul>
<li><a class="reference internal" href="#discussion-of-project-or-task-results">Discussion of project or task results</a></li>
<li><a class="reference internal" href="#list-of-departures-from-assumptions-set-in-the-planning-phase-of-the-model">List of departures from assumptions set in the planning phase of the model</a></li>
<li><a class="reference internal" href="#report-on-limitations-on-use-of-output-data-for-decision-makers-or-users">Report on limitations on use of output data for decision makers or users</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#references">REFERENCES</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="api.html"
                        title="previous chapter">API</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="publications.html"
                        title="next chapter">Publications</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/qapp.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="publications.html" title="Publications"
             >next</a> |</li>
        <li class="right" >
          <a href="api.html" title="API"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">übertool alpha documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2014, EPA übertool team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>